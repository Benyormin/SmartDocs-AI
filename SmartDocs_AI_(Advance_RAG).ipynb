{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP3UKeBSd+zChxw+7uSTKZy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benyormin/SmartDocs-AI/blob/main/SmartDocs_AI_(Advance_RAG).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing requirements"
      ],
      "metadata": {
        "id": "KN-fzfP-TcNc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LDdbiCh4u6w4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3746f215-6f5c-4d5c-8210-a34a9cc4c234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "langchain\n",
        "python-dotenv\n",
        "streamlit\n",
        "unstructured[all-docs]\n",
        "tiktoken\n",
        "faiss-cpu\n",
        "libmagic\n",
        "python-magic\n",
        "langchain-google-genai\n",
        "google-generativeai\n",
        "pyngrok\n",
        "langchain_community\n",
        "langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hffPAzL-PzMl",
        "outputId": "c8a46dc7-76cb-4d4c-80ab-9e89432272b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for libmagic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup API Keys"
      ],
      "metadata": {
        "id": "uclGAd7IThBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should replace your own API keys and Tokens here"
      ],
      "metadata": {
        "id": "IU4XnwqpTjf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GOOGLE_API_KEY= \"Your_GOOGLE_API_KEY\"\n",
        "NGROK_TOKEN = \"Your_NGROK_TOKEN\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QgJR-Za761N",
        "outputId": "00e4c95f-0649-410e-d58c-4b8f82aa194e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main code"
      ],
      "metadata": {
        "id": "NpthBNvLKAnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import time\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from dotenv import load_dotenv\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "import pandas as pd\n",
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.document_loaders import UnstructuredExcelLoader\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@st.cache_resource(show_spinner=\"Loading embedding model...\")\n",
        "def load_embedding_model():\n",
        "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    return HuggingFaceEmbeddings(model_name=model_name)\n",
        "\n",
        "st.title(\"SmartDocs AI 🤖\")\n",
        "st.sidebar.title(\"Sources 🛠️\")\n",
        "\n",
        "uploaded_docs = []\n",
        "url_docs = []\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "llm = GoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=GOOGLE_API_KEY, temperature= 0)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=['\\n\\n', '\\n', '.', ','],\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap  = 150\n",
        ")\n",
        "embeddings = load_embedding_model()\n",
        "\n",
        "\n",
        "def load_uploaded_files(uploaded_files):\n",
        "    results = []\n",
        "    for file in uploaded_files:\n",
        "        filename = file.name\n",
        "        file_extension = filename.split('.')[-1].lower()\n",
        "\n",
        "        # Save uploaded file to a temporary file on disk\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=f\".{file_extension}\") as tmp_file:\n",
        "            tmp_file.write(file.getbuffer())\n",
        "            tmp_path = tmp_file.name\n",
        "\n",
        "        try:\n",
        "            if file_extension == \"txt\":\n",
        "                text_loader = TextLoader(tmp_path)\n",
        "                data = text_loader.load()\n",
        "                results.extend(data)  # load() returns list of Document objects\n",
        "\n",
        "            elif file_extension == \"csv\":\n",
        "                csv_loader = CSVLoader(tmp_path)\n",
        "                data = csv_loader.load()\n",
        "                results.extend(data)\n",
        "\n",
        "            elif file_extension in [\"xls\", \"xlsx\"]:\n",
        "                excel_loader = UnstructuredExcelLoader(tmp_path)\n",
        "                data = excel_loader.load()\n",
        "                results.extend(data)\n",
        "\n",
        "            elif file_extension == \"pdf\":\n",
        "                pdf_loader = UnstructuredPDFLoader(tmp_path)\n",
        "                data = pdf_loader.load()\n",
        "                results.extend(data)\n",
        "        finally:\n",
        "            # Clean up the temporary file\n",
        "            os.unlink(tmp_path)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "\n",
        "# Initialize session state for URL list\n",
        "if \"urls\" not in st.session_state:\n",
        "    st.session_state.urls = []\n",
        "if \"new_url\" not in st.session_state:\n",
        "    st.session_state.new_url = \"\"\n",
        "\n",
        "# Input for a new URL (not tied to list yet)\n",
        "st.session_state.new_url = st.sidebar.text_input(\"Enter new URL\")\n",
        "\n",
        "# Add URL when button clicked\n",
        "if st.sidebar.button(\"➕ Add URL\"):\n",
        "    url = st.session_state.new_url.strip()\n",
        "    if url:\n",
        "        st.session_state.urls.append(url)\n",
        "        st.success(f\"Added URL: {url}\")\n",
        "        st.session_state.new_url = \"\"  # Clear input\n",
        "\n",
        "# Show current list of URLs\n",
        "if st.session_state.urls:\n",
        "    st.sidebar.markdown(\"### ✅ Added URLs\")\n",
        "    for idx, url in enumerate(st.session_state.urls, 1):\n",
        "        st.sidebar.markdown(f\"{idx}. {url}\")\n",
        "else:\n",
        "    st.sidebar.info(\"No URLs added yet.\")\n",
        "\n",
        "if st.sidebar.button(\"❌ Clear URLs\"):\n",
        "    st.session_state.urls = []\n",
        "\n",
        "urls = st.session_state.get(\"urls\", [])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"faiss_store.pkl\"\n",
        "\n",
        "##uploading logic\n",
        "\n",
        "uploaded_files = st.sidebar.file_uploader(\n",
        "    \"Upload one or more files (.txt, .csv, .pdf, .xls/.xlsx)\",\n",
        "    type=[\"txt\", \"csv\", \"pdf\", \"xls\", \"xlsx\"],\n",
        "    accept_multiple_files=True\n",
        ")\n",
        "\n",
        "\n",
        "process_files_btn = st.sidebar.button(\"Process Sources\")\n",
        "\n",
        "main_placeholder = st.empty()\n",
        "\n",
        "\n",
        "if uploaded_files and process_files_btn:\n",
        "    uploaded_docs = load_uploaded_files(uploaded_files)\n",
        "    if (len(uploaded_docs)>0):\n",
        "      main_placeholder.text(\"Files Loading...Started...✅✅✅\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if process_files_btn:\n",
        "    # load data\n",
        "    if urls:\n",
        "      loader = UnstructuredURLLoader(urls=urls)\n",
        "      main_placeholder.text(\"Processing URLs...✅✅✅\")\n",
        "      url_docs = loader.load()\n",
        "\n",
        "\n",
        "\n",
        "    all_docs = uploaded_docs + url_docs\n",
        "    main_placeholder.text(\"Text Splitter...Started...✅✅✅\")\n",
        "    docs = text_splitter.split_documents(all_docs)\n",
        "    # create embeddings and save it to FAISS index\n",
        "\n",
        "\n",
        "\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "    main_placeholder.text(\"Embedding Vector Started Building...✅✅✅\")\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Save the FAISS index to a pickle file\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        pickle.dump(vectorstore, f)\n",
        "\n",
        "query = main_placeholder.text_input(\"Question: \")\n",
        "if query:\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            vectorstore = pickle.load(f)\n",
        "            chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())\n",
        "            result = chain({\"question\": query}, return_only_outputs=True)\n",
        "            # result will be a dictionary of this format --> {\"answer\": \"\", \"sources\": [] }\n",
        "\n",
        "\n",
        "            st.header(\"Answer\")\n",
        "            st.write(result[\"answer\"])\n",
        "\n",
        "            # Display sources, if available\n",
        "            sources = result.get(\"sources\", \"\")\n",
        "            if sources:\n",
        "                st.subheader(\"Sources:\")\n",
        "                sources_list = sources.split(\"\\n\")  # Split the sources by newline\n",
        "                for source in sources_list:\n",
        "                    st.write(source)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrtrvgoqYZkt",
        "outputId": "8d855a6d-f85b-4cc4-e738-4dcd39620a22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the server"
      ],
      "metadata": {
        "id": "aRKKX-G4T2W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from pyngrok import ngrok, conf\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "\n",
        "# Kill existing tunnels (if any)\n",
        "ngrok.kill()\n",
        "\n",
        "# Set your authtoken\n",
        "load_dotenv()\n",
        "\n",
        "conf.get_default().auth_token = os.getenv(\"NGROK_TOKEN\")\n",
        "\n",
        "# Start tunnel explicitly with protocol\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"Streamlit app link:\", public_url)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0-J_3DedYXJw",
        "outputId": "59c11287-6dde-4346-a002-33662110570f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app link: NgrokTunnel: \"https://a9bb-34-80-48-84.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Streamlit"
      ],
      "metadata": {
        "id": "PvK4piZhT7KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "XXfo-ISiYXdd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hj50u0-ndRgR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}